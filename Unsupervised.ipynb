{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "0.9977528878901724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28426\n",
      "           1       0.40      0.35      0.37        55\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.70      0.67      0.69     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from Resampling import data, upsampled, downsampled, y, outlier_fraction\n",
    "\n",
    "\n",
    "\"\"\"The first unsupervised algorithm I will be trying is the isolation forest \n",
    "algorithm with the original data (cut to 10% of its original size for faster\n",
    "computation). \"\"\"\n",
    "\n",
    "# Re-setting X to the data minus the Class feature\n",
    "X = data.drop('Class', axis=1)\n",
    "\n",
    "# Fitting the model\n",
    "a = IsolationForest(max_samples=len(X), contamination=outlier_fraction).fit(X)\n",
    "\n",
    "# Prediction\n",
    "y_prediction = a.predict(X)\n",
    "\n",
    "y_prediction[y_prediction == 1] = 0  # Valid transactions are labelled as 0.\n",
    "y_prediction[y_prediction == -1] = 1  # Fraudulent transactions are labelled as 1.\n",
    "\n",
    "errors = (y_prediction != y).sum()  # Total number of errors is calculated.\n",
    "\n",
    "print(errors)\n",
    "print(accuracy_score(y_prediction, y))\n",
    "print(classification_report(y_prediction, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7152\n",
      "0.8322623012336413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83     21319\n",
      "           1       0.83      0.83      0.83     21319\n",
      "\n",
      "    accuracy                           0.83     42638\n",
      "   macro avg       0.83      0.83      0.83     42638\n",
      "weighted avg       0.83      0.83      0.83     42638\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe upsampled dataset has much better precision and recall for finding fraudulent transactions,\\nand is overall much more accurate at finding out which data points are fraudulent. However, it\\nonly correctly identifies around 82% of non-fraudulent cases as opposed to with the original data,\\nwhere every single non-fraudulent case was identified.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Now, let's try the same isolation forest algorithm with a randomly upsampled dataset with \n",
    "21326 fraudulent and 21326 valid transactions, where the outlier fraction\n",
    "is .5\"\"\"\n",
    "\n",
    "X = upsampled.drop('Class', axis=1)\n",
    "y = upsampled.Class\n",
    "\n",
    "# New model with 50% contamination because there are equal amounts of fraud and valid\n",
    "b = IsolationForest(max_samples=len(X), contamination=.50).fit(X)\n",
    "\n",
    "# Prediction\n",
    "y_prediction2 = b.predict(X)\n",
    "\n",
    "y_prediction2[y_prediction2 == 1] = 0  # Valid transactions are labelled as 0.\n",
    "y_prediction2[y_prediction2 == -1] = 1  # Fraudulent transactions are labelled as 1.\n",
    "\n",
    "errors2 = (y_prediction2 != y).sum()  # Total number of errors is calculated.\n",
    "\n",
    "print(errors2)\n",
    "print(accuracy_score(y_prediction2, y))\n",
    "print(classification_report(y_prediction2, y))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The upsampled dataset has much better precision and recall for finding fraudulent transactions,\n",
    "and is overall much more accurate at finding out which data points are fraudulent. However, it\n",
    "only correctly identifies around 82% of non-fraudulent cases as opposed to with the original data,\n",
    "where every single non-fraudulent case was identified.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9964888873283944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28426\n",
      "           1       0.02      0.02      0.02        55\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.51      0.51      0.51     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\"Next, we will try the local outlier factor algorithm. First, we will use the original\n",
    "dataset (but 1/10 of the original size)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Reset the variables for X and y for the original data\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data.Class # y is output\n",
    "\n",
    "# Initialize a model with 20 neighbors\n",
    "c = LocalOutlierFactor(n_neighbors = 20,contamination = outlier_fraction)\n",
    "# Fit the model\n",
    "y_prediction3 = c._fit_predict(X)\n",
    "y_prediction3[y_prediction3 == 1] = 0 # Valid transactions are labelled as 0.\n",
    "y_prediction3[y_prediction3 == -1] = 1 # Fraudulent transactions are labelled as 1.\n",
    "\n",
    "errors3 = (y_prediction3 != y).sum()\n",
    "print(accuracy_score(y_prediction3,y))\n",
    "print(classification_report(y_prediction3,y))\n",
    "\n",
    "\"\"\"\n",
    "Both the precision and recall are pretty low, meaning that this is not a good algorithm to apply\n",
    "to this dataset. This is partly due to the fact that there are so many more non-fraud data points\n",
    "than fraud data points, so it is difficult to draw a line between the LOF of fraud and non-fraud cases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17207655143299405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.26      0.29     28656\n",
      "           1       0.00      0.00      0.00     13982\n",
      "\n",
      "    accuracy                           0.17     42638\n",
      "   macro avg       0.17      0.13      0.15     42638\n",
      "weighted avg       0.23      0.17      0.20     42638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Next, I will try the same LOF algorithm, but with the upsampled dataset this time to try to offset\n",
    "some of the errors in precision and accuracy.\n",
    "\"\"\"\n",
    "\n",
    "X = upsampled.drop('Class', axis=1)\n",
    "y = upsampled.Class\n",
    "\n",
    "# Initialize a model with 20 neighbors\n",
    "d = LocalOutlierFactor(n_neighbors = 20,contamination = .5)\n",
    "y_prediction4 = d._fit_predict(X)\n",
    "y_prediction4[y_prediction4 == 1] = 0 \n",
    "y_prediction4[y_prediction4 == -1] = 1\n",
    "\n",
    "errors4 = (y_prediction4 != y).sum()\n",
    "print(accuracy_score(y_prediction4,y))\n",
    "print(classification_report(y_prediction4,y))\n",
    "\n",
    "\"\"\"\n",
    "Unfortunately, it is even worse when there are equal amounts of fraudulent and non-fraudulent cases.\n",
    "In conclusion, isolation forest on an upsampled dataset is the best option for this dataset.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
